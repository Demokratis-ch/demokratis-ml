{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Add the project root directory to the Python path\n",
    "project_root = os.path.abspath(os.path.join(current_dir, '..', '..', '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Run a quick validation that we have an entry for the OPEN_API_KEY within environment variables\n",
    "assert \"OPENAI_API_KEY\" in os.environ, \"OPENAI_API_KEY environment variable must be set\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Parsing Model as mlflow \"Model from code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing tmp/chatgpt_file_upload_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"tmp/chatgpt_file_upload_model.py\"\n",
    "\n",
    "import os\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "from openai import files\n",
    "from typing import List, Dict, Any\n",
    "from mlflow.pyfunc import PythonModel\n",
    "from mlflow.models import set_model\n",
    "import asyncio\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "class ChatgptFileParsing(PythonModel):\n",
    "    def __init__(self):\n",
    "        self.client = AsyncOpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "        self.model_str = \"gpt-4o\"\n",
    "\n",
    "        # Define the prompt\n",
    "        self.prompt = \"\"\"Answer from file context:\n",
    "        This PDF is a German document proposing an amendment to a Swiss federal law, or introducing a new federal law. \n",
    "        Parse the document structure and return it in JSON format.\n",
    "        - Respond with only JSON without using markdown code blocks.\n",
    "        - The structure (or outline) should be a hierarchy of titles, sections, articles etc. There may also be one or more appendices.\n",
    "        - A section title consists of a roman numeral.\n",
    "        - Make sure you don't skip any headings and text inside paragraphs.\n",
    "        - Itemize each paragraph inside the articles as well.\n",
    "        - For each article, put its title separately from the actual paragraphs.\n",
    "        - For each paragraph, include its number or letter (as in the original document) in a separate JSON item.\n",
    "        - When there is a letter-indexed list inside of a paragraph, break out the list items as children of the paragraph. Make sure to place the index (letter or number) separately from the list item text.\n",
    "        - Place footnotes in their own JSON element. Replace the references to footnotes in the text with '{{footnote_id}}'.\n",
    "        - List all sections in the document.\n",
    "        - List all articles for each section.\n",
    "        - List all paragraphs for each article.\n",
    "        - Return a valid json. Don't fill in placeholders like \"// List articles under this section\".\n",
    "\n",
    "        JSON structure:\n",
    "        {\n",
    "            \"document_title\": \"\",\n",
    "            \"amendment\": \"\",\n",
    "            \"sections\": [\n",
    "                {\n",
    "                \"section\": \"\",\n",
    "                \"articles\": [\n",
    "                    \"article\": \"\",\n",
    "                    \"title\": \"\",\n",
    "                    \"minorities\": \"\",\n",
    "                    \"text\": \"\",\n",
    "                    \"paragraphs\": [\n",
    "                    {\n",
    "                        \"number\": \"\",\n",
    "                        \"text\": \"\",\n",
    "                        \"list\": [\n",
    "                        {\n",
    "                            \"index\": \"\",\n",
    "                            \"text\": \"\",\n",
    "                        },\n",
    "                        ]\n",
    "                    },\n",
    "                    ],\n",
    "                ],\n",
    "                },\n",
    "            ],\n",
    "            \"footnotes\": [\n",
    "                {\n",
    "                \"footnote_id\": \"\",\n",
    "                \"text\": \"\",\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "    async def upload_file(self, filename: str) -> Dict[str, Any]:\n",
    "        # Upload the file to OpenAI\n",
    "        file = await self.client.files.create(\n",
    "            file=open(filename, \"rb\"), \n",
    "            purpose=\"assistants\"\n",
    "        )\n",
    "        return file\n",
    "\n",
    "    async def delete_file(self, file_id):\n",
    "        # Delete file from OpenAI\n",
    "        try:\n",
    "            response = await self.client.files.delete(file_id)\n",
    "            print(f\"File {file_id} deleted successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete file {file_id}: {e}\")\n",
    "\n",
    "    async def parse_file(self, file_path: str, semaphore: asyncio.Semaphore) -> Dict[str, str]:\n",
    "        async with semaphore:\n",
    "            # Upload the file to OpenAI\n",
    "            print(f\"Uploading file {file_path}...\")\n",
    "            file = await self.upload_file(file_path)\n",
    "\n",
    "            # Create assistant\n",
    "            pdf_assistant = await self.client.beta.assistants.create(\n",
    "                name=\"PDF assistant\",\n",
    "                model=self.model_str,\n",
    "                description=\"An assistant to extract the contents of PDF files.\",\n",
    "                tools=[{\"type\": \"file_search\"}]\n",
    "            )\n",
    "\n",
    "            # Create thread\n",
    "            thread = await self.client.beta.threads.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": self.prompt,\n",
    "                    # Attach the new file to the message.\n",
    "                    \"attachments\": [\n",
    "                        { \"file_id\": file.id, \"tools\": [{\"type\": \"file_search\"}] }\n",
    "                    ],\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # Run thread\n",
    "            print(\"Running thread...\")\n",
    "            run = await self.client.beta.threads.runs.create_and_poll(\n",
    "                thread_id=thread.id, \n",
    "                assistant_id=pdf_assistant.id, \n",
    "                timeout=60\n",
    "            )\n",
    "            print(\"Thread completed.\")\n",
    "\n",
    "            run_status = await self.client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "            print(run_status.status)\n",
    "            if run_status.status != 'completed':\n",
    "                return {'status': run_status.status}, run.usage.prompt_tokens, run.usage.completion_tokens\n",
    "\n",
    "            # Get messages\n",
    "            # messages = await self.client.beta.threads.messages.list(thread_id=thread.id)\n",
    "\n",
    "            messages_cursor = await self.client.beta.threads.messages.list(thread_id=thread.id)\n",
    "            messages = [message for message in messages_cursor]\n",
    "            # print(messages)\n",
    "\n",
    "            # Output text\n",
    "            text_res = messages[0][1][0].content[0].text.value\n",
    "\n",
    "            # Convert text to JSON\n",
    "            dict_res = json.loads(text_res)\n",
    "                                \n",
    "            # Delete file from OpenAI\n",
    "            await self.delete_file(file.id)\n",
    "\n",
    "        return dict_res, run.usage.prompt_tokens, run.usage.completion_tokens\n",
    "\n",
    "\n",
    "    async def predict(self, context, model_input: List[str]) -> List[Dict[str, Any]]:\n",
    "        max_concurrent_tasks = 3\n",
    "        semaphore = asyncio.Semaphore(max_concurrent_tasks)\n",
    "        tasks = [self.parse_file(filename, semaphore) for filename in model_input]\n",
    "\n",
    "        results = await asyncio.gather(*tasks)\n",
    "\n",
    "        parsed_dicts, num_input_tokens, num_output_tokens = zip(*results)            \n",
    "        \n",
    "        # # Use multiprocessing to parse multiple files concurrently\n",
    "        # with multiprocessing.Pool() as pool:\n",
    "        #     results = pool.map(parse_file, model_input)\n",
    "\n",
    "        return parsed_dicts, num_input_tokens, num_output_tokens\n",
    "        \n",
    "        # results = []\n",
    "        # num_input_tokens = []\n",
    "        # num_output_tokens = []\n",
    "        # for file in model_input:\n",
    "        #     parsed_dict, num_input_token, num_output_token = parse_file(file)\n",
    "        #     results.append(parsed_dict)\n",
    "        #     num_input_tokens.append(num_input_token)\n",
    "        #     num_output_tokens.append(num_output_token)\n",
    "        \n",
    "        # return results, num_input_tokens, num_output_tokens\n",
    "\n",
    "\n",
    "# Specify which definition in this script represents the model instance\n",
    "set_model(ChatgptFileParsing())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test PDF Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('../sample-documents/51276-de-DRAFT-92be4e18116eab4615da2a4279771eb05b4f47e2.pdf'), PosixPath('../sample-documents/bp6wfzuy - zg - Entwurf des totalrevidierten Gesetzes ueber Ausbildungsbeitraege (ID 2565).pdf'), PosixPath('../sample-documents/jpxdh228 - zh - Entwurf-1_(EnerG-Aenderung-Staerkung-Versorgungssicherheit_Vernehmlassung).pdf')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>pypdf2_text</th>\n",
       "      <th>pdfminer_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../sample-documents/51276-de-DRAFT-92be4e18116...</td>\n",
       "      <td>\\n«$$e-seal» «$$QrCode »\\n2024-... «%ASFF_YYYY...</td>\n",
       "      <td>«$$QrCode»\\n Vorentwurf\\n «$$e-seal»\\n Änderun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../sample-documents/bp6wfzuy - zg - Entwurf de...</td>\n",
       "      <td>Kanton Zug [Fundst. od. Gesch.-Nr.] (ID 2565)\\...</td>\n",
       "      <td>Kanton Zug\\n[Fundst. od. Gesch.-Nr.] (ID 2565)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../sample-documents/jpxdh228 - zh - Entwurf-1_...</td>\n",
       "      <td>\\n Kanton Zürich\\nBaudirektion\\nVernehmlassung...</td>\n",
       "      <td>Entwurf\\n26. August 2021\\nKanton Zürich\\nBaudi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path  \\\n",
       "0  ../sample-documents/51276-de-DRAFT-92be4e18116...   \n",
       "1  ../sample-documents/bp6wfzuy - zg - Entwurf de...   \n",
       "2  ../sample-documents/jpxdh228 - zh - Entwurf-1_...   \n",
       "\n",
       "                                         pypdf2_text  \\\n",
       "0  \\n«$$e-seal» «$$QrCode »\\n2024-... «%ASFF_YYYY...   \n",
       "1  Kanton Zug [Fundst. od. Gesch.-Nr.] (ID 2565)\\...   \n",
       "2  \\n Kanton Zürich\\nBaudirektion\\nVernehmlassung...   \n",
       "\n",
       "                                       pdfminer_text  \n",
       "0  «$$QrCode»\\n Vorentwurf\\n «$$e-seal»\\n Änderun...  \n",
       "1  Kanton Zug\\n[Fundst. od. Gesch.-Nr.] (ID 2565)...  \n",
       "2  Entwurf\\n26. August 2021\\nKanton Zürich\\nBaudi...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataset\n",
    "\n",
    "from pathlib import Path\n",
    "from src.preprocessing import preprocess\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Get all file paths in the 'sample-documents' folder\n",
    "sample_documents_dir = Path('../sample-documents')\n",
    "file_paths = list(sample_documents_dir.glob('**/*'))\n",
    "print(file_paths)\n",
    "\n",
    "test_df = pd.DataFrame([str(s) for s in file_paths], columns=[\"file_path\"])\n",
    "\n",
    "test_df[\"pypdf2_text\"] = test_df[\"file_path\"].apply(lambda x: preprocess.extract_text_from_pdf(x, \"PyPDF2\"))    \n",
    "test_df[\"pdfminer_text\"] = test_df[\"file_path\"].apply(lambda x: preprocess.extract_text_from_pdf(x, \"pdfminer\"))    \n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Parsing Model and Log to mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/01 14:49:41 INFO mlflow.types.utils: Unsupported type hint: typing.List[typing.Dict[str, typing.Any]], skipping schema inference\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51276-de-DRAFT-92be4e18116eab4615da2a4279771eb05b4f47e2_parsed.json\n",
      "51276-de-DRAFT-92be4e18116eab4615da2a4279771eb05b4f47e2_pypdf2.html\n",
      "bp6wfzuy - zg - Entwurf des totalrevidierten Gesetzes ueber Ausbildungsbeitraege (ID 2565)_parsed.json\n",
      "bp6wfzuy - zg - Entwurf des totalrevidierten Gesetzes ueber Ausbildungsbeitraege (ID 2565)_pypdf2.html\n",
      "jpxdh228 - zh - Entwurf-1_(EnerG-Aenderung-Staerkung-Versorgungssicherheit_Vernehmlassung)_parsed.json\n",
      "jpxdh228 - zh - Entwurf-1_(EnerG-Aenderung-Staerkung-Versorgungssicherheit_Vernehmlassung)_pypdf2.html\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from src.evaluation import evaluate\n",
    "import json\n",
    "\n",
    "mlflow.set_experiment(\"structure-extraction\")\n",
    "\n",
    "model_path = \"tmp/chatgpt_file_upload_model.py\"\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Log the model\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        python_model=model_path,\n",
    "        artifact_path=\"chagpt_file_upload_model\",\n",
    "        #input_example=[\"../sample-documents/51276-de-DRAFT-92be4e18116eab4615da2a4279771eb05b4f47e2.pdf\"],\n",
    "    )\n",
    "\n",
    "    # Load the model\n",
    "    model = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "\n",
    "    # Predict\n",
    "    parsed_dicts, num_input_tokens, num_output_tokens = await model.predict(test_df[\"file_path\"].tolist())\n",
    "    test_df[\"parsed_dicts\"] = parsed_dicts\n",
    "    test_df[\"num_input_tokens\"] = num_input_tokens\n",
    "    test_df[\"num_output_tokens\"] = num_output_tokens\n",
    "\n",
    "    mlflow.log_param(\"model\", model.unwrap_python_model().model_str)\n",
    "\n",
    "    mlflow.log_metric(\"num_files\", len(test_df))\n",
    "    mlflow.log_metric(\"parsed_files\", sum([p.get(\"status\") != \"failed\" for p in test_df[\"parsed_dicts\"].tolist()]))\n",
    "    \n",
    "    mlflow.log_metric(\"num_input_tokens\", sum(num_input_tokens))\n",
    "    mlflow.log_metric(\"num_output_tokens\", sum(num_output_tokens))\n",
    "    \n",
    "    percnt_missing_characters, percnt_added_characters = evaluate.percnt_missing_and_added_characters(parsed_dicts, test_df[\"pypdf2_text\"].tolist())\n",
    "    test_df[\"avg_percnt_missing_chars_pypdf2\"] = percnt_missing_characters\n",
    "    test_df[\"avg_percnt_added_chars_pypdf2\"] = percnt_added_characters\n",
    "    mlflow.log_metric(\"avg_percnt_missing_chars_pypdf2\", sum(percnt_missing_characters) / len(test_df))\n",
    "    mlflow.log_metric(\"avg_percnt_added_chars_pypdf2\", sum(percnt_added_characters) / len(test_df))\n",
    "\n",
    "    percnt_missing_characters, percnt_added_characters = evaluate.percnt_missing_and_added_characters(parsed_dicts, test_df[\"pdfminer_text\"].tolist())\n",
    "    test_df[\"avg_percnt_missing_chars_pdfminer\"] = percnt_missing_characters\n",
    "    test_df[\"avg_percnt_added_chars_pdfminer\"] = percnt_added_characters\n",
    "    mlflow.log_metric(\"avg_percnt_missing_chars_pdfminer\", sum(percnt_missing_characters) / len(test_df))\n",
    "    mlflow.log_metric(\"avg_percnt_added_chars_pdfminer\", sum(percnt_added_characters) / len(test_df))\n",
    "\n",
    "    costs = evaluate.get_costs(\n",
    "        model.unwrap_python_model().model_str, \n",
    "        num_input_tokens, \n",
    "        num_output_tokens\n",
    "    )\n",
    "    test_df[\"costs\"] = costs\n",
    "    mlflow.log_metric(\"costs\", test_df[\"costs\"].sum())\n",
    "\n",
    "    mlflow.log_artifact(model_path)\n",
    "    \n",
    "    test_df[\"html_diff_pypdf2\"] = evaluate.compare_texts_html(parsed_dicts, test_df[\"pypdf2_text\"])\n",
    "    test_df[\"html_diff_pdfminer\"] = evaluate.compare_texts_html(parsed_dicts, test_df[\"pdfminer_text\"])\n",
    "    \n",
    "    # Log the parsed dictionaries and HTML diffs\n",
    "    for idx, row in test_df.iterrows():\n",
    "        filename_parsed = row[\"file_path\"].split('/')[-1].replace(\".pdf\", \"_parsed.json\")\n",
    "        print(filename_parsed)\n",
    "        mlflow.log_text(json.dumps(row[\"parsed_dicts\"], indent=4), filename_parsed)\n",
    "\n",
    "        filename_pypdf2 = row[\"file_path\"].split('/')[-1].replace(\".pdf\", \"_pypdf2.html\")\n",
    "        print(filename_pypdf2)\n",
    "        mlflow.log_text(row[\"html_diff_pypdf2\"], filename_pypdf2)\n",
    "\n",
    "        filename_pdfminer = row[\"file_path\"].split('/')[-1].replace(\".pdf\", \"_pdfminer.html\")\n",
    "        mlflow.log_text(row[\"html_diff_pdfminer\"], filename_pdfminer)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demokratis-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
